# -*- coding: utf-8 -*-
"""app.py

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1teCrbBATsmhaZiymcsjC0mPExk8zT8CT
"""

pip install pandas numpy scikit-learn tensorflow

pip install SpeechRecognition

pip install pandas scikit-learn joblib

pip install googletrans==4.0.0-rc1

#Hindi call
import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import classification_report, accuracy_score
import joblib
import speech_recognition as sr

# -------------------- TRAINING --------------------

# Load dataset
df = pd.read_csv("/content/hindi_call_records_dataset.csv")

# TF-IDF Vectorizer
vectorizer = TfidfVectorizer(max_features=5000)
X = vectorizer.fit_transform(df['text'])
y = df['label']

# Split and train
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)
model = LogisticRegression()
model.fit(X_train, y_train)

# Evaluate
y_pred = model.predict(X_test)
print("Accuracy:", accuracy_score(y_test, y_pred))
print("\nClassification Report:\n", classification_report(y_test, y_pred))

# Save model and vectorizer
joblib.dump(model, "hindi_fraud_model.pkl")
joblib.dump(vectorizer, "hindi_vectorizer.pkl")

# -------------------- AUDIO PREDICTION --------------------

def predict_from_audio(audio_path):
    recognizer = sr.Recognizer()
    with sr.AudioFile(audio_path) as source:
        audio_data = recognizer.record(source)
        try:
            # Transcribe Hindi speech
            text = recognizer.recognize_google(audio_data, language="hi-IN")
            print(f"Transcribed Text: {text}")

            # Load model/vectorizer
            model = joblib.load("hindi_fraud_model.pkl")
            vectorizer = joblib.load("hindi_vectorizer.pkl")

            # Predict
            features = vectorizer.transform([text])
            prediction = model.predict(features)[0]
            print(f"Prediction: {prediction}")
            return prediction
        except sr.UnknownValueError:
            print("Could not understand audio.")
        except sr.RequestError as e:
            print(f"API error: {e}")

# Example usage (provide path to .wav or .flac file)
predict_from_audio("/content/ElevenLabs_Text_to_Speech_audio.wav")
predict_from_audio("/content/ElevenLabs_Text_to_Speech_audio (1).wav")

#Telugu call
import os
import pickle
import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
from tensorflow.keras.preprocessing.text import Tokenizer
from tensorflow.keras.preprocessing.sequence import pad_sequences
from tensorflow.keras.models import Sequential, load_model
from tensorflow.keras.layers import Embedding, LSTM, Dense, Dropout

# Paths
MODEL_PATH = "telugu_call_classifier.h5"
TOKENIZER_PATH = "tokenizer.pkl"

# Load the dataset
df = pd.read_csv("/content/telugu_call_dataset.csv")

# Encode labels (fraud=1, real=0)
df['label'] = df['label'].map({'fraud': 1, 'real': 0})

# Prepare data
X = df['transcript'].astype(str).values
y = df['label'].values

# Tokenizer setup
if os.path.exists(TOKENIZER_PATH):
    print("Loading existing tokenizer...")
    with open(TOKENIZER_PATH, 'rb') as f:
        tokenizer = pickle.load(f)
else:
    print("Creating new tokenizer...")
    tokenizer = Tokenizer(num_words=10000, oov_token="<OOV>")
    tokenizer.fit_on_texts(X)
    with open(TOKENIZER_PATH, 'wb') as f:
        pickle.dump(tokenizer, f)
    print(f"Tokenizer saved to {TOKENIZER_PATH}")

# Convert text to padded sequences
sequences = tokenizer.texts_to_sequences(X)
max_len = max(len(seq) for seq in sequences)
X_pad = pad_sequences(sequences, maxlen=max_len, padding='post')

# Split data
X_train, X_test, y_train, y_test = train_test_split(X_pad, y, test_size=0.2, random_state=42)

# Model setup
if os.path.exists(MODEL_PATH):
    print("Loading existing model...")
    model = load_model(MODEL_PATH)
else:
    print("Training new model...")
    model = Sequential([
        Embedding(input_dim=10000, output_dim=64, input_length=max_len),
        LSTM(64, return_sequences=False),
        Dropout(0.5),
        Dense(1, activation='sigmoid')
    ])
    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])
    model.fit(X_train, y_train, epochs=5, batch_size=32, validation_split=0.1)
    model.save(MODEL_PATH)
    print(f"Model saved to {MODEL_PATH}")

# Evaluate model
loss, accuracy = model.evaluate(X_test, y_test)
print(f"Test Accuracy: {accuracy:.4f}")

# === User Input Prediction ===
def predict_call(transcript):
    seq = tokenizer.texts_to_sequences([transcript])
    padded = pad_sequences(seq, maxlen=max_len, padding='post')
    prediction = model.predict(padded)[0][0]
    label = "Fraud" if prediction >= 0.5 else "Real"
    print(f"\nCall Prediction: {label} (Confidence: {prediction:.4f})")

# Get input from user
user_input = input("\nEnter a call transcript to check if it's fraud or real:\n")
predict_call(user_input)

#telugu/hindi prediction
import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.naive_bayes import MultinomialNB
from sklearn.pipeline import Pipeline
from sklearn.metrics import classification_report
import joblib
import os

# File paths
hindi_path = "hindi_sms_dataset.csv"
telugu_path = "telugu_sms_dataset.csv"

def load_dataset(language):
    if language == "hindi":
        df = pd.read_csv(hindi_path)
    elif language == "telugu":
        df = pd.read_csv(telugu_path)
    else:
        raise ValueError("Unsupported language selected.")

    assert 'Text' in df.columns and 'Label' in df.columns, "Dataset must contain 'Text' and 'Label' columns"
    return df

def train_or_load_model(df, language):
    model_filename = f"{language}_fraud_classifier.pkl"

    # Load existing model if available
    if os.path.exists(model_filename):
        print(f"Loading existing model from {model_filename}")
        model = joblib.load(model_filename)
    else:
        print("Training new model...")
        X = df['Text']
        y = df['Label']
        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

        model = Pipeline([
            ('tfidf', TfidfVectorizer(max_features=5000, ngram_range=(1, 2))),
            ('clf', MultinomialNB())
        ])

        model.fit(X_train, y_train)

        y_pred = model.predict(X_test)
        print("\nClassification Report:")
        print(classification_report(y_test, y_pred))

        joblib.dump(model, model_filename)
        print(f"Model saved as {model_filename}")

    return model

def predict_interactive(model):
    print("\nYou can now enter your messages. Type 'exit' to quit.")
    while True:
        user_input = input("Enter a message: ").strip()
        if user_input.lower() == "exit":
            print("Exiting prediction mode.")
            break
        prediction = model.predict([user_input])[0]
        print(f"Prediction: {'Fraud' if prediction == 1 or prediction == 'fraud' else 'Real'}\n")

def main():
    language = input("Choose language (hindi/telugu): ").strip().lower()
    df = load_dataset(language)
    print(f"Loaded {len(df)} messages for training in {language.title()}")

    model = train_or_load_model(df, language)
    predict_interactive(model)

if __name__ == "__main__":
    main()



#english
import pandas as pd
import numpy as np
import librosa
import librosa.display
import speech_recognition as sr
import tensorflow as tf
import pickle
import os
from tensorflow.keras.models import Sequential, load_model
from tensorflow.keras.layers import LSTM, Dense, Dropout, Bidirectional, Embedding
from tensorflow.keras.optimizers import Adam
from sklearn.model_selection import train_test_split

# File paths for model and tokenizer
CALL_MODEL_PATH = "call_model.h5"
MSG_MODEL_PATH = "msg_model.h5"
CALL_TOKENIZER_PATH = "call_tokenizer.pkl"
MSG_TOKENIZER_PATH = "msg_tokenizer.pkl"

# Load datasets
call_data_path = "/content/updated_metadata_with_call_type_filled.csv"
message_data_path = "/content/fraud_call_modified.csv"

call_df = pd.read_csv(call_data_path)
message_df = pd.read_csv(message_data_path)

# Ensure required columns exist for call classification
if "call_type" not in call_df.columns or "transcript" not in call_df.columns:
    raise ValueError("The call dataset must contain 'call_type' and 'transcript' columns.")

# Ensure required columns exist for message classification
if "Label" not in message_df.columns or "Text" not in message_df.columns:
    raise ValueError("The message dataset must contain 'Label' and 'Text' columns.")

# Convert labels to binary
call_df['call_type'] = call_df['call_type'].map({'Fraud Call': 1, 'Normal Call': 0})
message_df['Label'] = message_df['Label'].map({'fraud': 1, 'normal': 0})

# Drop missing values
call_df.dropna(inplace=True)
message_df.dropna(inplace=True)

# Text tokenization and padding function
def preprocess_text(data, max_words=10000, max_length=200):
    tokenizer = tf.keras.preprocessing.text.Tokenizer(num_words=max_words, oov_token="<OOV>")
    tokenizer.fit_on_texts(data)
    sequences = tokenizer.texts_to_sequences(data)
    padded_sequences = tf.keras.preprocessing.sequence.pad_sequences(sequences, maxlen=max_length, padding="post")
    return tokenizer, padded_sequences

# Check if models already exist
if os.path.exists(CALL_MODEL_PATH) and os.path.exists(MSG_MODEL_PATH):
    print("Loading existing models...")
    call_model = load_model(CALL_MODEL_PATH)
    msg_model = load_model(MSG_MODEL_PATH)

    # Load tokenizers
    with open(CALL_TOKENIZER_PATH, 'rb') as f:
        call_tokenizer = pickle.load(f)
    with open(MSG_TOKENIZER_PATH, 'rb') as f:
        msg_tokenizer = pickle.load(f)

else:
    print("Training models...")

    # Prepare call data
    X_train_call, X_test_call, y_train_call, y_test_call = train_test_split(
        call_df['transcript'], call_df['call_type'], test_size=0.2, random_state=42, stratify=call_df['call_type']
    )

    call_tokenizer, X_train_call_padded = preprocess_text(X_train_call)
    X_test_call_padded = call_tokenizer.texts_to_sequences(X_test_call)
    X_test_call_padded = tf.keras.preprocessing.sequence.pad_sequences(X_test_call_padded, maxlen=200, padding="post")

    # Prepare message data
    X_train_msg, X_test_msg, y_train_msg, y_test_msg = train_test_split(
        message_df['Text'], message_df['Label'], test_size=0.2, random_state=42, stratify=message_df['Label']
    )

    msg_tokenizer, X_train_msg_padded = preprocess_text(X_train_msg)
    X_test_msg_padded = msg_tokenizer.texts_to_sequences(X_test_msg)
    X_test_msg_padded = tf.keras.preprocessing.sequence.pad_sequences(X_test_msg_padded, maxlen=200, padding="post")

    # Build LSTM model
    def build_lstm_model(input_dim=10000, output_dim=128, input_length=200):
        model = Sequential([
            Embedding(input_dim=input_dim, output_dim=output_dim, input_length=input_length),
            Bidirectional(LSTM(64, return_sequences=True)),
            Dropout(0.5),
            Bidirectional(LSTM(32)),
            Dense(32, activation='relu'),
            Dropout(0.5),
            Dense(1, activation='sigmoid')  # Binary classification
        ])
        model.compile(loss='binary_crossentropy', optimizer=Adam(learning_rate=0.001), metrics=['accuracy'])
        return model

    # Train LSTM for call classification
    call_model = build_lstm_model()
    call_model.fit(X_train_call_padded, y_train_call, validation_data=(X_test_call_padded, y_test_call), epochs=10, batch_size=32)

    # Train LSTM for message classification
    msg_model = build_lstm_model()
    msg_model.fit(X_train_msg_padded, y_train_msg, validation_data=(X_test_msg_padded, y_test_msg), epochs=10, batch_size=32)

    # Save models
    call_model.save(CALL_MODEL_PATH)
    msg_model.save(MSG_MODEL_PATH)

    # Save tokenizers
    with open(CALL_TOKENIZER_PATH, 'wb') as f:
        pickle.dump(call_tokenizer, f)
    with open(MSG_TOKENIZER_PATH, 'wb') as f:
        pickle.dump(msg_tokenizer, f)

    print("Models trained and saved!")

# Function to classify messages
def classify_message(text):
    input_seq = msg_tokenizer.texts_to_sequences([text])
    input_padded = tf.keras.preprocessing.sequence.pad_sequences(input_seq, maxlen=200, padding="post")
    prediction = msg_model.predict(input_padded)[0][0]
    return "Fraud Message" if prediction >= 0.5 else "Normal Message"

# Function to classify audio calls
def classify_audio(audio_path):
    recognizer = sr.Recognizer()
    try:
        with sr.AudioFile(audio_path) as source:
            recognizer.adjust_for_ambient_noise(source)
            audio_data = recognizer.record(source)
            transcript = recognizer.recognize_google(audio_data)

        input_seq = call_tokenizer.texts_to_sequences([transcript])
        input_padded = tf.keras.preprocessing.sequence.pad_sequences(input_seq, maxlen=200, padding="post")
        prediction = call_model.predict(input_padded)[0][0]
        return "Fraud Call" if prediction >= 0.5 else "Normal Call"
    except Exception as e:
        return f"Error processing audio: {e}"

# Main function for user input
if __name__ == "__main__":
    choice = input("Enter '1' to classify a message or '2' to classify an audio file: ")
    if choice == '1':
        text = input("Enter the message: ")
        print(f"Message Classification: {classify_message(text)}")
    elif choice == '2':
        audio_path = input("Enter the path to the call recording: ")
        print(f"Call Classification: {classify_audio(audio_path)}")

import pandas as pd
import numpy as np
import librosa
import librosa.display
import speech_recognition as sr
import tensorflow as tf
import pickle
import os
from tensorflow.keras.models import Sequential, load_model
from tensorflow.keras.layers import LSTM, Dense, Dropout, Bidirectional, Embedding
from tensorflow.keras.optimizers import Adam
from sklearn.model_selection import train_test_split

# File paths for model and tokenizer
CALL_MODEL_PATH = "call_model.h5"
MSG_MODEL_PATH = "msg_model.h5"
CALL_TOKENIZER_PATH = "call_tokenizer.pkl"
MSG_TOKENIZER_PATH = "msg_tokenizer.pkl"

# Load datasets
call_data_path = "/content/updated_metadata_with_call_type_filled.csv"
message_data_path = "/content/fraud_call_modified.csv"

call_df = pd.read_csv(call_data_path)
message_df = pd.read_csv(message_data_path)

# Ensure required columns exist for call classification
if "call_type" not in call_df.columns or "transcript" not in call_df.columns:
    raise ValueError("The call dataset must contain 'call_type' and 'transcript' columns.")

# Ensure required columns exist for message classification
if "Label" not in message_df.columns or "Text" not in message_df.columns:
    raise ValueError("The message dataset must contain 'Label' and 'Text' columns.")

# Convert labels to binary
call_df['call_type'] = call_df['call_type'].map({'Fraud Call': 1, 'Normal Call': 0})
message_df['Label'] = message_df['Label'].map({'fraud': 1, 'normal': 0})

# Drop missing values
call_df.dropna(inplace=True)
message_df.dropna(inplace=True)

# Text tokenization and padding function
def preprocess_text(data, max_words=10000, max_length=200):
    tokenizer = tf.keras.preprocessing.text.Tokenizer(num_words=max_words, oov_token="<OOV>")
    tokenizer.fit_on_texts(data)
    sequences = tokenizer.texts_to_sequences(data)
    padded_sequences = tf.keras.preprocessing.sequence.pad_sequences(sequences, maxlen=max_length, padding="post")
    return tokenizer, padded_sequences

# Check if models already exist
if os.path.exists(CALL_MODEL_PATH) and os.path.exists(MSG_MODEL_PATH):
    print("Loading existing models...")
    call_model = load_model(CALL_MODEL_PATH)
    msg_model = load_model(MSG_MODEL_PATH)

    # Load tokenizers
    with open(CALL_TOKENIZER_PATH, 'rb') as f:
        call_tokenizer = pickle.load(f)
    with open(MSG_TOKENIZER_PATH, 'rb') as f:
        msg_tokenizer = pickle.load(f)

else:
    print("Training models...")

    # Prepare call data
    X_train_call, X_test_call, y_train_call, y_test_call = train_test_split(
        call_df['transcript'], call_df['call_type'], test_size=0.2, random_state=42, stratify=call_df['call_type']
    )

    call_tokenizer, X_train_call_padded = preprocess_text(X_train_call)
    X_test_call_padded = call_tokenizer.texts_to_sequences(X_test_call)
    X_test_call_padded = tf.keras.preprocessing.sequence.pad_sequences(X_test_call_padded, maxlen=200, padding="post")

    # Prepare message data
    X_train_msg, X_test_msg, y_train_msg, y_test_msg = train_test_split(
        message_df['Text'], message_df['Label'], test_size=0.2, random_state=42, stratify=message_df['Label']
    )

    msg_tokenizer, X_train_msg_padded = preprocess_text(X_train_msg)
    X_test_msg_padded = msg_tokenizer.texts_to_sequences(X_test_msg)
    X_test_msg_padded = tf.keras.preprocessing.sequence.pad_sequences(X_test_msg_padded, maxlen=200, padding="post")

    # Build LSTM model
    def build_lstm_model(input_dim=10000, output_dim=128, input_length=200):
        model = Sequential([
            Embedding(input_dim=input_dim, output_dim=output_dim, input_length=input_length),
            Bidirectional(LSTM(64, return_sequences=True)),
            Dropout(0.5),
            Bidirectional(LSTM(32)),
            Dense(32, activation='relu'),
            Dropout(0.5),
            Dense(1, activation='sigmoid')  # Binary classification
        ])
        model.compile(loss='binary_crossentropy', optimizer=Adam(learning_rate=0.001), metrics=['accuracy'])
        return model

    # Train LSTM for call classification
    call_model = build_lstm_model()
    call_model.fit(X_train_call_padded, y_train_call, validation_data=(X_test_call_padded, y_test_call), epochs=10, batch_size=32)

    # Train LSTM for message classification
    msg_model = build_lstm_model()
    msg_model.fit(X_train_msg_padded, y_train_msg, validation_data=(X_test_msg_padded, y_test_msg), epochs=10, batch_size=32)

    # Save models
    call_model.save(CALL_MODEL_PATH)
    msg_model.save(MSG_MODEL_PATH)

    # Save tokenizers
    with open(CALL_TOKENIZER_PATH, 'wb') as f:
        pickle.dump(call_tokenizer, f)
    with open(MSG_TOKENIZER_PATH, 'wb') as f:
        pickle.dump(msg_tokenizer, f)

    print("Models trained and saved!")

# Function to classify messages
def classify_message(text):
    input_seq = msg_tokenizer.texts_to_sequences([text])
    input_padded = tf.keras.preprocessing.sequence.pad_sequences(input_seq, maxlen=200, padding="post")
    prediction = msg_model.predict(input_padded)[0][0]
    return "Fraud Message" if prediction >= 0.5 else "Normal Message"

# Function to classify audio calls
def classify_audio(audio_path):
    recognizer = sr.Recognizer()
    try:
        with sr.AudioFile(audio_path) as source:
            recognizer.adjust_for_ambient_noise(source)
            audio_data = recognizer.record(source)
            transcript = recognizer.recognize_google(audio_data)

        input_seq = call_tokenizer.texts_to_sequences([transcript])
        input_padded = tf.keras.preprocessing.sequence.pad_sequences(input_seq, maxlen=200, padding="post")
        prediction = call_model.predict(input_padded)[0][0]
        return "Fraud Call" if prediction >= 0.5 else "Normal Call"
    except Exception as e:
        return f"Error processing audio: {e}"

# Main function for user input
if __name__ == "__main__":
    choice = input("Enter '1' to classify a message or '2' to classify an audio file: ")
    if choice == '1':
        text = input("Enter the message: ")
        print(f"Message Classification: {classify_message(text)}")
    elif choice == '2':
        audio_path = input("Enter the path to the call recording: ")
        print(f"Call Classification: {classify_audio(audio_path)}")
    else:
        print("Invalid choice.")

pip install pandas numpy scikit-learn tensorflow speechrecognition joblib

# yeh main code hai
import os
import joblib
import pickle
import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.naive_bayes import MultinomialNB
from sklearn.linear_model import LogisticRegression
from sklearn.pipeline import Pipeline
from sklearn.metrics import classification_report, accuracy_score
import speech_recognition as sr
import tensorflow as tf
from tensorflow.keras.models import Sequential, load_model
from tensorflow.keras.preprocessing.text import Tokenizer
from tensorflow.keras.preprocessing.sequence import pad_sequences
from tensorflow.keras.layers import Embedding, LSTM, Dense, Dropout

# -------------------- CONFIG --------------------

DATA_PATHS = {
    "hindi_sms": "hindi_sms_dataset.csv",
    "telugu_sms": "telugu_sms_dataset.csv",
    "hindi_call": "hindi_call_records_dataset.csv",
    "telugu_call": "telugu_call_dataset.csv",
}

MODEL_PATHS = {
    "hindi_sms": "hindi_fraud_classifier.pkl",
    "telugu_sms": "telugu_fraud_classifier.pkl",
    "hindi_call": {
        "model": "hindi_fraud_model.pkl",
        "vectorizer": "hindi_vectorizer.pkl"
    },
    "telugu_call": {
        "model": "telugu_call_classifier.h5",
        "tokenizer": "tokenizer.pkl"
    }
}

# Load English models and tokenizers
CALL_MODEL_PATH_EN = "call_model.h5"
MSG_MODEL_PATH_EN = "msg_model.h5"
CALL_TOKENIZER_PATH_EN = "call_tokenizer.pkl"
MSG_TOKENIZER_PATH_EN = "msg_tokenizer.pkl"

call_model_en = load_model(CALL_MODEL_PATH_EN)
msg_model_en = load_model(MSG_MODEL_PATH_EN)

with open(CALL_TOKENIZER_PATH_EN, 'rb') as f:
    call_tokenizer_en = pickle.load(f)

with open(MSG_TOKENIZER_PATH_EN, 'rb') as f:
    msg_tokenizer_en = pickle.load(f)

# -------------------- ENGLISH FUNCTIONS --------------------

def classify_english_message(text):
    input_seq = msg_tokenizer_en.texts_to_sequences([text])
    input_padded = tf.keras.preprocessing.sequence.pad_sequences(input_seq, maxlen=200, padding="post")
    prediction = msg_model_en.predict(input_padded)[0][0]
    return "Fraud Message" if prediction >= 0.5 else "Normal Message"

def classify_english_audio(audio_path):
    recognizer = sr.Recognizer()
    try:
        with sr.AudioFile(audio_path) as source:
            recognizer.adjust_for_ambient_noise(source)
            audio_data = recognizer.record(source)
            transcript = recognizer.recognize_google(audio_data)

        input_seq = call_tokenizer_en.texts_to_sequences([transcript])
        input_padded = tf.keras.preprocessing.sequence.pad_sequences(input_seq, maxlen=200, padding="post")
        prediction = call_model_en.predict(input_padded)[0][0]
        return "Fraud Call" if prediction >= 0.5 else "Normal Call"
    except Exception as e:
        return f"Error processing audio: {e}"

# -------------------- SMS MODEL TRAIN/LOAD --------------------

def load_sms_dataset(language):
    key = f"{language}_sms"
    df = pd.read_csv(DATA_PATHS[key])
    assert 'Text' in df.columns and 'Label' in df.columns, "Dataset must contain 'Text' and 'Label' columns"
    return df

def train_or_load_sms_model(df, language):
    filename = MODEL_PATHS[f"{language}_sms"]
    if os.path.exists(filename):
        print(f"Loading existing SMS model from {filename}")
        return joblib.load(filename)

    print("Training new SMS model...")
    X = df['Text']
    y = df['Label']
    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)
    model = Pipeline([
        ('tfidf', TfidfVectorizer(max_features=5000, ngram_range=(1, 2))),
        ('clf', MultinomialNB())
    ])
    model.fit(X_train, y_train)
    print(classification_report(y_test, model.predict(X_test)))
    joblib.dump(model, filename)
    return model

# -------------------- HINDI CALL --------------------

def train_or_load_hindi_call_model():
    model_file = MODEL_PATHS['hindi_call']['model']
    vec_file = MODEL_PATHS['hindi_call']['vectorizer']

    if os.path.exists(model_file) and os.path.exists(vec_file):
        return joblib.load(model_file), joblib.load(vec_file)

    df = pd.read_csv(DATA_PATHS['hindi_call'])
    vectorizer = TfidfVectorizer(max_features=5000)
    X = vectorizer.fit_transform(df['text'])
    y = df['label']

    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)
    model = LogisticRegression()
    model.fit(X_train, y_train)

    print("Hindi Call Accuracy:", accuracy_score(y_test, model.predict(X_test)))
    print(classification_report(y_test, model.predict(X_test)))

    joblib.dump(model, model_file)
    joblib.dump(vectorizer, vec_file)
    return model, vectorizer

def predict_hindi_call_from_audio(audio_path):
    model, vectorizer = train_or_load_hindi_call_model()
    recognizer = sr.Recognizer()
    with sr.AudioFile(audio_path) as source:
        audio_data = recognizer.record(source)
        try:
            text = recognizer.recognize_google(audio_data, language="hi-IN")
            features = vectorizer.transform([text])
            prediction = model.predict(features)[0]
            print(f"Prediction: {'Fraud' if prediction == 1 else 'Real'}")
        except Exception as e:
            print(f"Speech recognition error: {e}")

# -------------------- TELUGU CALL --------------------

def train_or_load_telugu_call_model():
    model_file = MODEL_PATHS['telugu_call']['model']
    tokenizer_file = MODEL_PATHS['telugu_call']['tokenizer']
    df = pd.read_csv(DATA_PATHS['telugu_call'])
    df['label'] = df['label'].map({'fraud': 1, 'real': 0})
    X = df['transcript'].astype(str).values
    y = df['label'].values

    if os.path.exists(tokenizer_file):
        with open(tokenizer_file, 'rb') as f:
            tokenizer = pickle.load(f)
    else:
        tokenizer = Tokenizer(num_words=10000, oov_token="<OOV>")
        tokenizer.fit_on_texts(X)
        with open(tokenizer_file, 'wb') as f:
            pickle.dump(tokenizer, f)

    sequences = tokenizer.texts_to_sequences(X)
    max_len = max(len(seq) for seq in sequences)
    X_pad = pad_sequences(sequences, maxlen=max_len, padding='post')
    X_train, X_test, y_train, y_test = train_test_split(X_pad, y, test_size=0.2, random_state=42)

    if os.path.exists(model_file):
        model = load_model(model_file)
    else:
        model = Sequential([
            Embedding(input_dim=10000, output_dim=64, input_length=max_len),
            LSTM(64),
            Dropout(0.5),
            Dense(1, activation='sigmoid')
        ])
        model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])
        model.fit(X_train, y_train, epochs=5, batch_size=32, validation_split=0.1)
        model.save(model_file)

    return model, tokenizer, max_len

def predict_telugu_call(text):
    model, tokenizer, max_len = train_or_load_telugu_call_model()
    seq = tokenizer.texts_to_sequences([text])
    padded = pad_sequences(seq, maxlen=max_len, padding='post')
    prediction = model.predict(padded)[0][0]
    label = "Fraud" if prediction >= 0.5 else "Real"
    print(f"Prediction: {label} (Confidence: {prediction:.4f})")

# -------------------- CLI --------------------

def interactive_mode():
    while True:
        print("\nSelect option:")
        print("1. Predict Hindi SMS")
        print("2. Predict Telugu SMS")
        print("3. Predict Hindi Call from Audio")
        print("4. Predict Telugu Call from Transcript")
        print("5. Predict English SMS")
        print("6. Predict English Call from Audio")
        print("7. Exit")

        choice = input("Enter choice (1-7): ").strip()

        if choice == '1':
            df = load_sms_dataset('hindi')
            model = train_or_load_sms_model(df, 'hindi')
            while True:
                text = input("Enter SMS (or 'exit'): ")
                if text.lower() == 'exit':
                    break
                pred = model.predict([text])[0]
                print("Prediction:", 'Fraud' if pred == 1 or pred == 'fraud' else 'Real')

        elif choice == '2':
            df = load_sms_dataset('telugu')
            model = train_or_load_sms_model(df, 'telugu')
            while True:
                text = input("Enter SMS (or 'exit'): ")
                if text.lower() == 'exit':
                    break
                pred = model.predict([text])[0]
                print("Prediction:", 'Fraud' if pred == 1 or pred == 'fraud' else 'Real')

        elif choice == '3':
            path = input("Enter path to Hindi audio file: ")
            predict_hindi_call_from_audio(path)

        elif choice == '4':
            text = input("Enter Telugu call transcript: ")
            predict_telugu_call(text)

        elif choice == '5':
            while True:
                text = input("Enter English SMS (or 'exit'): ")
                if text.lower() == 'exit':
                    break
                prediction = classify_english_message(text)
                print("Prediction:", prediction)

        elif choice == '6':
            path = input("Enter path to English audio file (.wav): ")
            prediction = classify_english_audio(path)
            print("Prediction:", prediction)

        elif choice == '7':
            print("Exiting.")
            break

        else:
            print("Invalid option.")

# -------------------- MAIN --------------------

if __name__ == "__main__":
    interactive_mode()

# Commented out IPython magic to ensure Python compatibility.
# #utils.py
# %%writefile utils.py
# import os
# import joblib
# import pickle
# import pandas as pd
# import numpy as np
# import speech_recognition as sr
# import tensorflow as tf
# from tensorflow.keras.models import load_model
# from tensorflow.keras.preprocessing.sequence import pad_sequences
# 
# # Load all models once
# 
# # Paths (adjust these paths as needed)
# MODEL_DIR = "models"
# 
# # English Models and Tokenizers
# call_model_en = load_model(os.path.join(MODEL_DIR, "/content/call_model.h5"))
# msg_model_en = load_model(os.path.join(MODEL_DIR, "/content/msg_model.h5"))
# with open(os.path.join(MODEL_DIR, "/content/call_tokenizer.pkl"), 'rb') as f:
#     call_tokenizer_en = pickle.load(f)
# with open(os.path.join(MODEL_DIR, "/content/msg_tokenizer.pkl"), 'rb') as f:
#     msg_tokenizer_en = pickle.load(f)
# 
# # Hindi SMS model
# hindi_sms_model = joblib.load(os.path.join(MODEL_DIR, "/content/hindi_fraud_classifier.pkl"))
# 
# # Telugu SMS model
# telugu_sms_model = joblib.load(os.path.join(MODEL_DIR, "/content/telugu_fraud_classifier.pkl"))
# 
# # Hindi call model + vectorizer
# hindi_call_model = joblib.load(os.path.join(MODEL_DIR, "/content/hindi_fraud_model.pkl"))
# hindi_call_vectorizer = joblib.load(os.path.join(MODEL_DIR, "/content/hindi_vectorizer.pkl"))
# 
# # Telugu call model + tokenizer + max_len
# telugu_call_model = load_model(os.path.join(MODEL_DIR, "/content/telugu_call_classifier.h5"))
# with open(os.path.join(MODEL_DIR, "/content/tokenizer.pkl"), 'rb') as f:
#     telugu_call_tokenizer = pickle.load(f)
# # You need to fix max_len for Telugu call padding
# # Best to save max_len in a file or hardcode after inspecting training
# TELUGU_MAX_LEN = 100  # Example, adjust as per your training max_len
# 
# # --- Functions ---
# 
# def classify_english_message(text):
#     seq = msg_tokenizer_en.texts_to_sequences([text])
#     padded = pad_sequences(seq, maxlen=200, padding='post')
#     pred = msg_model_en.predict(padded)[0][0]
#     return "Fraud Message" if pred >= 0.5 else "Normal Message"
# 
# def classify_english_audio(audio_path):
#     recognizer = sr.Recognizer()
#     try:
#         with sr.AudioFile(audio_path) as source:
#             recognizer.adjust_for_ambient_noise(source)
#             audio = recognizer.record(source)
#             transcript = recognizer.recognize_google(audio)
#         seq = call_tokenizer_en.texts_to_sequences([transcript])
#         padded = pad_sequences(seq, maxlen=200, padding='post')
#         pred = call_model_en.predict(padded)[0][0]
#         return "Fraud Call" if pred >= 0.5 else "Normal Call"
#     except Exception as e:
#         return f"Error: {e}"
# 
# def predict_hindi_sms(text):
#     pred = hindi_sms_model.predict([text])[0]
#     return "Fraud" if pred == 1 or pred == 'fraud' else "Real"
# 
# def predict_telugu_sms(text):
#     pred = telugu_sms_model.predict([text])[0]
#     return "Fraud" if pred == 1 or pred == 'fraud' else "Real"
# 
# def predict_hindi_call_from_audio(audio_path):
#     recognizer = sr.Recognizer()
#     try:
#         with sr.AudioFile(audio_path) as source:
#             audio = recognizer.record(source)
#             text = recognizer.recognize_google(audio, language="hi-IN")
#         features = hindi_call_vectorizer.transform([text])
#         pred = hindi_call_model.predict(features)[0]
#         return "Fraud Call" if pred == 1 else "Real Call"
#     except Exception as e:
#         return f"Error: {e}"
# 
# def predict_telugu_call(text):
#     seq = telugu_call_tokenizer.texts_to_sequences([text])
#     padded = pad_sequences(seq, maxlen=TELUGU_MAX_LEN, padding='post')
#     pred = telugu_call_model.predict(padded)[0][0]
#     return "Fraud Call" if pred >= 0.5 else "Real Call"
#

# Commented out IPython magic to ensure Python compatibility.
# #app.py
# %%writefile app.py
# import streamlit as st
# import os
# import joblib
# import pickle
# import pandas as pd
# import tensorflow as tf
# import speech_recognition as sr
# from tensorflow.keras.models import load_model
# from tensorflow.keras.preprocessing.sequence import pad_sequences
# 
# # ---------- Load English models ----------
# CALL_MODEL_PATH_EN = "call_model.h5"
# MSG_MODEL_PATH_EN = "msg_model.h5"
# CALL_TOKENIZER_PATH_EN = "call_tokenizer.pkl"
# MSG_TOKENIZER_PATH_EN = "msg_tokenizer.pkl"
# 
# call_model_en = load_model(CALL_MODEL_PATH_EN)
# msg_model_en = load_model(MSG_MODEL_PATH_EN)
# 
# with open(CALL_TOKENIZER_PATH_EN, 'rb') as f:
#     call_tokenizer_en = pickle.load(f)
# with open(MSG_TOKENIZER_PATH_EN, 'rb') as f:
#     msg_tokenizer_en = pickle.load(f)
# 
# # ---------- Utility Functions ----------
# def classify_english_message(text):
#     input_seq = msg_tokenizer_en.texts_to_sequences([text])
#     input_padded = pad_sequences(input_seq, maxlen=200, padding="post")
#     prediction = msg_model_en.predict(input_padded)[0][0]
#     return "üö® Fraud Message" if prediction >= 0.5 else "‚úÖ Normal Message"
# 
# def classify_english_audio(audio_file):
#     recognizer = sr.Recognizer()
#     with sr.AudioFile(audio_file) as source:
#         recognizer.adjust_for_ambient_noise(source)
#         audio_data = recognizer.record(source)
#     try:
#         transcript = recognizer.recognize_google(audio_data)
#         input_seq = call_tokenizer_en.texts_to_sequences([transcript])
#         input_padded = pad_sequences(input_seq, maxlen=200, padding="post")
#         prediction = call_model_en.predict(input_padded)[0][0]
#         return "üö® Fraud Call" if prediction >= 0.5 else "‚úÖ Normal Call"
#     except Exception as e:
#         return f"‚ùå Error: {e}"
# 
# # ---------- Streamlit UI ----------
# st.set_page_config(page_title="Multilingual Fraud Detection", layout="wide")
# st.title("üì± Multilingual Fraud Detection (SMS & Call)")
# st.markdown("Detect fraud in **English**, **Hindi**, and **Telugu** for messages and calls.")
# 
# option = st.sidebar.selectbox(
#     "Choose an option",
#     (
#         "English SMS",
#         "English Call (Audio)",
#         "Hindi SMS",
#         "Telugu SMS",
#         "Hindi Call (Audio)",
#         "Telugu Call (Transcript)"
#     )
# )
# 
# if option == "English SMS":
#     st.subheader("‚úâÔ∏è English SMS Classification")
#     text = st.text_area("Enter SMS text:")
#     if st.button("Predict"):
#         result = classify_english_message(text)
#         st.success(result)
# 
# elif option == "English Call (Audio)":
#     st.subheader("üìû English Call Classification")
#     audio = st.file_uploader("Upload a .wav audio file", type=["wav"])
#     if st.button("Predict") and audio:
#         result = classify_english_audio(audio)
#         st.success(result)
# 
# elif option == "Hindi SMS":
#     st.subheader("‚úâÔ∏è Hindi SMS Classification")
#     from main import load_sms_dataset, train_or_load_sms_model
#     df = load_sms_dataset("hindi")
#     model = train_or_load_sms_model(df, "hindi")
#     text = st.text_area("Enter Hindi SMS:")
#     if st.button("Predict"):
#         pred = model.predict([text])[0]
#         result = "üö® Fraud" if pred == 1 or pred == 'fraud' else "‚úÖ Real"
#         st.success(result)
# 
# elif option == "Telugu SMS":
#     st.subheader("‚úâÔ∏è Telugu SMS Classification")
#     from main import load_sms_dataset, train_or_load_sms_model
#     df = load_sms_dataset("telugu")
#     model = train_or_load_sms_model(df, "telugu")
#     text = st.text_area("Enter Telugu SMS:")
#     if st.button("Predict"):
#         pred = model.predict([text])[0]
#         result = "üö® Fraud" if pred == 1 or pred == 'fraud' else "‚úÖ Real"
#         st.success(result)
# 
# elif option == "Hindi Call (Audio)":
#     st.subheader("üìû Hindi Call Classification")
#     from main import predict_hindi_call_from_audio
#     audio = st.file_uploader("Upload Hindi call audio (.wav)", type=["wav"])
#     if st.button("Predict") and audio:
#         with open("temp_hindi.wav", "wb") as f:
#             f.write(audio.read())
#         result = predict_hindi_call_from_audio("temp_hindi.wav")
#         st.success("Prediction done (see console/logs).")
# 
# elif option == "Telugu Call (Transcript)":
#     st.subheader("üìû Telugu Call Transcript Classification")
#     from main import predict_telugu_call
#     text = st.text_area("Enter Telugu call transcript:")
#     if st.button("Predict"):
#         result = predict_telugu_call(text)
#         st.success("Prediction done (see console/logs).")
#

from google.colab import files
files.download('utils.py')
files.download('app.py')

pip install streamlit

import streamlit as st

st.title("Multilingual Fraud Detection")

text = st.text_area("Enter the message or call transcript:")

if st.button("Predict"):
    # yahan tumhara prediction function call karo
    result = "Fraud"  # example, yahan apni prediction logic lagao
    st.write("Prediction:", result)